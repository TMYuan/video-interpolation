{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import utils\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook\n",
    "import models.dcgan_unet_64 as dcgan_unet_models\n",
    "import models.dcgan_64 as dcgan_models\n",
    "import models.classifiers as classifiers\n",
    "import models.my_model as my_model\n",
    "from data.moving_mnist import MovingMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "# random.seed(1)\n",
    "# torch.manual_seed(1)\n",
    "# torch.cuda.manual_seed_all(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-3\n",
    "seq_len = 12\n",
    "beta1 = 0.5\n",
    "content_dim = 128\n",
    "pose_dim = 50\n",
    "channels = 3\n",
    "normalize = False\n",
    "sd_nf = 100\n",
    "image_width = 64\n",
    "batch_size = 100\n",
    "log_dir = './logs/0529_noiseLikePoseVector_advTraining/'\n",
    "os.makedirs(os.path.join(log_dir, 'rec'), exist_ok=True)\n",
    "os.makedirs(os.path.join(log_dir, 'analogy'), exist_ok=True)\n",
    "os.makedirs(os.path.join(log_dir, 'gen'), exist_ok=True)\n",
    "logging.basicConfig(filename=os.path.join(log_dir, 'record.txt'), level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MovingMNIST(True, '../data_uni/', seq_len=seq_len)\n",
    "test_data = MovingMNIST(False, '../data_uni/', seq_len=seq_len)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=16,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_encoder(\n",
      "  (main): Sequential(\n",
      "    (0): dcgan_conv(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (1): dcgan_conv(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (2): dcgan_conv(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (3): dcgan_conv(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (4): Conv2d(512, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Tanh()\n",
      "  )\n",
      ")\n",
      "pose_encoder(\n",
      "  (c1): dcgan_conv(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(5, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (c2): dcgan_conv(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(66, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (c3): dcgan_conv(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(130, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (c4): dcgan_conv(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(258, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (c5): Sequential(\n",
      "    (0): Conv2d(514, 50, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "decoder(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(178, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): dcgan_upconv(\n",
      "      (main): Sequential(\n",
      "        (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (4): dcgan_upconv(\n",
      "      (main): Sequential(\n",
      "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (5): dcgan_upconv(\n",
      "      (main): Sequential(\n",
      "        (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (6): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "CondDiscriminator(\n",
      "  (c1): dcgan_conv(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(5, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (c2): dcgan_conv(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(66, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (c3): dcgan_conv(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(130, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (c4): dcgan_conv(\n",
      "    (main): Sequential(\n",
      "      (0): Conv2d(258, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (D): Sequential(\n",
      "    (0): Conv2d(514, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # netEC = dcgan_unet_models.content_encoder(content_dim, channels).to(device)\n",
    "# netEC = dcgan_models.content_encoder(content_dim, channels).to(device)\n",
    "# netEP = dcgan_models.pose_encoder(pose_dim, channels).to(device)\n",
    "# # netD = dcgan_unet_models.decoder(content_dim, pose_dim, channels).to(device)\n",
    "# netD = dcgan_models.decoder(content_dim, pose_dim, channels).to(device)\n",
    "# netC = classifiers.scene_discriminator(pose_dim, sd_nf).to(device)\n",
    "\n",
    "netEC = my_model.content_encoder(content_dim, channels).to(device)\n",
    "netEP = my_model.pose_encoder(pose_dim, channels, conditional=True).to(device)\n",
    "netG = my_model.decoder(content_dim, pose_dim, channels).to(device)\n",
    "# netC = my_model.scene_discriminator(pose_dim, sd_nf).to(device)\n",
    "# netC = my_model.Discriminator(channels).to(device)\n",
    "netD = my_model.CondDiscriminator(channels).to(device)\n",
    "\n",
    "netEC.apply(utils.weights_init)\n",
    "netEP.apply(utils.weights_init)\n",
    "netG.apply(utils.weights_init)\n",
    "netD.apply(utils.weights_init)\n",
    "\n",
    "print(netEC)\n",
    "print(netEP)\n",
    "print(netG)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerEC = optim.Adam(netEC.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerEP = optim.Adam(netEP.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- plotting funtions ------------------------------------\n",
    "def plot_rec(x, epoch, dtype):\n",
    "    x_c = x[0]\n",
    "    x_p = x[np.random.randint(1, len(x))]\n",
    "\n",
    "    h_c = netEC(x_c)\n",
    "    h_p = netEP(x_p, h_c)\n",
    "    rec = netG([h_c, h_p])\n",
    "\n",
    "    x_c, x_p, rec = x_c.data, x_p.data, rec.data\n",
    "    fname = '{}-{}.png'.format(dtype, epoch)\n",
    "    fname = os.path.join(log_dir, 'rec', fname)\n",
    "    to_plot = []\n",
    "    row_sz = 5\n",
    "    nplot = 20\n",
    "    for i in range(0, nplot-row_sz, row_sz):\n",
    "        row = [[xc, xp, xr] for xc, xp, xr in zip(x_c[i:i+row_sz], x_p[i:i+row_sz], rec[i:i+row_sz])]\n",
    "        to_plot.append(list(itertools.chain(*row)))\n",
    "    utils.save_tensors_image(fname, to_plot)\n",
    "\n",
    "def plot_analogy(x, epoch, dtype):\n",
    "    x_c = x[0]\n",
    "    h_c = netEC(x_c)\n",
    "    \n",
    "    nrow = 10\n",
    "    row_sz = len(x)\n",
    "    to_plot = []\n",
    "    row = [xi[0].data for xi in x]\n",
    "    zeros = torch.zeros(channels, image_width, image_width)\n",
    "    to_plot.append([zeros] + row)\n",
    "    for i in range(nrow):\n",
    "        to_plot.append([x[0][i].data])\n",
    "\n",
    "    for j in range(0, row_sz):\n",
    "        # for each time step\n",
    "        h_p = netEP(x[j], h_c).data\n",
    "        # first 10 pose vector, equal to first pose vector\n",
    "        for i in range(nrow):\n",
    "            h_p[i] = h_p[0]\n",
    "        rec = netG([h_c, h_p])\n",
    "        for i in range(nrow):\n",
    "            to_plot[i+1].append(rec[i].data.clone())\n",
    "\n",
    "    fname = '{}-{}.png'.format(dtype, epoch)\n",
    "    fname = os.path.join(log_dir, 'analogy', fname)\n",
    "    utils.save_tensors_image(fname, to_plot)\n",
    "    \n",
    "def plot_gen(x, epoch, dtype):\n",
    "    \"\"\"\n",
    "    Plot generation function\n",
    "    \"\"\"\n",
    "    x_c = x[0]\n",
    "    noise = torch.randn((batch_size, pose_dim, 1, 1), device=device)\n",
    "    \n",
    "    h_c = netEC(x_c)\n",
    "    gen = netG([h_c, noise])\n",
    "    \n",
    "    x_c, gen = x_c.data, gen.data\n",
    "    fname = '{}-{}.png'.format(dtype, epoch)\n",
    "    fname = os.path.join(log_dir, 'gen', fname)\n",
    "    to_plot = []\n",
    "    row_sz = 5\n",
    "    nplot = 15\n",
    "    \n",
    "    for i in range(0, nplot, row_sz):\n",
    "        row = [[xc, xg] for xc, xg in zip(x_c[i:i+row_sz], gen[i:i+row_sz])]\n",
    "        to_plot.append(list(itertools.chain(*row)))\n",
    "        \n",
    "    utils.save_tensors_image(fname, to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x):\n",
    "    x_c1 = x[np.random.randint(len(x))]\n",
    "    x_c2 = x[np.random.randint(len(x))]\n",
    "    x_p = x[np.random.randint(len(x))]\n",
    "    \n",
    "    \"\"\"\n",
    "    Train Discriminator\n",
    "    \"\"\"\n",
    "    optimizerD.zero_grad()\n",
    "    \n",
    "    h_c1 = netEC(x_c1)\n",
    "    \n",
    "    # Train with real sample\n",
    "    real_x = x_p\n",
    "    real_lbl = torch.full((batch_size,), 1, device=device)\n",
    "    out_real = netD(real_x, h_c1.detach())\n",
    "    errD_real = F.binary_cross_entropy(out_real, real_lbl)\n",
    "    errD_real.backward()\n",
    "    D_x = out_real.mean().item()\n",
    "    \n",
    "    # Train with fake sample\n",
    "    fake_lbl = torch.zeros((batch_size,), device=device)\n",
    "    noise = torch.randn((batch_size, pose_dim, 1, 1), device=device)\n",
    "    fake_x = netG([h_c1, noise])\n",
    "    out_fake = netD(fake_x.detach(), h_c1.detach())\n",
    "    errD_fake = F.binary_cross_entropy(out_fake, fake_lbl)\n",
    "    errD_fake.backward()\n",
    "    D_G_z1 = out_fake.mean().item()\n",
    "    \n",
    "    errD = errD_fake + errD_real\n",
    "    optimizerD.step()\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Train EC&EP&G\n",
    "    \"\"\"\n",
    "    optimizerEC.zero_grad()\n",
    "#     optimizerEP.zero_grad()\n",
    "    optimizerG.zero_grad()\n",
    "\n",
    "    # Adversarial loss\n",
    "    out_gen = netD(fake_x, h_c1)\n",
    "    errG = F.binary_cross_entropy(out_gen, real_lbl)\n",
    "    D_G_z2 = out_gen.mean().item()\n",
    "    \n",
    "    # Noise reconstruction loss\n",
    "#     noise_rec = netEP(fake_x, h_c1)\n",
    "#     errEP = F.mse_loss(noise_rec, noise)\n",
    "\n",
    "    # similarity loss: ||h_c1 - h_c2||\n",
    "    h_c2 = netEC(x_c2).detach()\n",
    "    errSim = F.mse_loss(h_c1, h_c2)\n",
    "\n",
    "    \n",
    "    # full loss\n",
    "#     errTotal = errG + errEP + errSim\\\n",
    "    errTotal = errG + errSim\n",
    "    errTotal.backward()\n",
    "\n",
    "    optimizerEC.step()\n",
    "#     optimizerEP.step()\n",
    "    optimizerG.step()\n",
    "\n",
    "#     return errD.item(), D_x, D_G_z1, errG.item(), errEP.item(), errSim.item(), D_G_z2\n",
    "    return errD.item(), D_x, D_G_z1, errG.item(), errSim.item(), D_G_z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcf20a5ff13416786b68fba2fff6a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='EPOCH', max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a48a4855a948c0a65a175cccc29095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00]errD: 27.5884| D(x): 0.9987| D(G(z1)): 0.9987| errG: 0.0000| errSim: 0.0331| D(G(z2)): 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35274cdb6834624bbe5af124c5502c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01]errD: 3.0280| D(x): 0.7330| D(G(z1)): 0.3196| errG: 3.0660| errSim: 0.0775| D(G(z2)): 0.2195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38708199cb0544c8b312be6d61f5bed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02]errD: 1.5185| D(x): 0.6973| D(G(z1)): 0.3091| errG: 2.4128| errSim: 0.0787| D(G(z2)): 0.2131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03019b89c00e4cc689c789e56377caea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03]errD: 0.8136| D(x): 0.7798| D(G(z1)): 0.2262| errG: 2.9123| errSim: 0.0559| D(G(z2)): 0.1516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d51696f0d0495a8e5f2982b759fef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04]errD: 0.4716| D(x): 0.8618| D(G(z1)): 0.1399| errG: 3.8142| errSim: 0.0630| D(G(z2)): 0.0979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb12f418d90a4eaebf5421c6d59e0773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05]errD: 0.3708| D(x): 0.8970| D(G(z1)): 0.1041| errG: 4.5672| errSim: 0.0756| D(G(z2)): 0.0671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3776501a98b6422ab6a32e8cab34a271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06]errD: 0.3107| D(x): 0.9117| D(G(z1)): 0.0890| errG: 4.5765| errSim: 0.0880| D(G(z2)): 0.0593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4d5e13091d421abb0d3317ded51d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07]errD: 0.2719| D(x): 0.9270| D(G(z1)): 0.0735| errG: 5.0836| errSim: 0.0987| D(G(z2)): 0.0480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d3ba0d130a48c792fea34379fb430a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08]errD: 0.2020| D(x): 0.9465| D(G(z1)): 0.0541| errG: 5.7003| errSim: 0.1175| D(G(z2)): 0.0303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d374e43292b24c358bb675138fc02fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09]errD: 0.1517| D(x): 0.9632| D(G(z1)): 0.0368| errG: 6.0414| errSim: 0.1345| D(G(z2)): 0.0197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a8e07e24db466c8333d08624373bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]errD: 0.2529| D(x): 0.9453| D(G(z1)): 0.0550| errG: 5.6012| errSim: 0.1449| D(G(z2)): 0.0325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a78433608214345ad8e9338b6b3d234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]errD: 0.1493| D(x): 0.9630| D(G(z1)): 0.0373| errG: 5.9786| errSim: 0.1650| D(G(z2)): 0.0197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7a1bd32027477498e6ff9222bd5e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]errD: 0.1379| D(x): 0.9683| D(G(z1)): 0.0313| errG: 6.5786| errSim: 0.1827| D(G(z2)): 0.0158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94386beb73364ba08071ca73b45708b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]errD: 0.2000| D(x): 0.9623| D(G(z1)): 0.0377| errG: 6.2313| errSim: 0.1880| D(G(z2)): 0.0197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a035c398e04f18b580b3048278b935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]errD: 0.1493| D(x): 0.9664| D(G(z1)): 0.0340| errG: 6.1228| errSim: 0.1926| D(G(z2)): 0.0183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffe8da5310b48c38db854c87236bc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]errD: 0.1286| D(x): 0.9698| D(G(z1)): 0.0302| errG: 6.0716| errSim: 0.2105| D(G(z2)): 0.0153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a29651939244b2f9611794d6cc841bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]errD: 0.1183| D(x): 0.9739| D(G(z1)): 0.0262| errG: 6.7545| errSim: 0.2101| D(G(z2)): 0.0121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d46d2ce9694c3eaf63910210ab6396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BATCH', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_size = len(train_loader)\n",
    "test_x = next(iter(test_loader))\n",
    "test_x = torch.transpose(test_x, 0, 1)\n",
    "test_x = test_x.to(device)\n",
    "\n",
    "for epoch in tqdm_notebook(range(200), desc='EPOCH'):\n",
    "    netEP.train()\n",
    "    netEC.train()\n",
    "    netD.train()\n",
    "    netG.train()\n",
    "    epoch_errSim, epoch_errG, epoch_errEP, epoch_errD = 0, 0, 0, 0\n",
    "    epoch_D_x, epoch_D_G_z1, epoch_D_G_z2 = 0, 0, 0\n",
    "    \n",
    "    for i, x in enumerate(tqdm_notebook(train_loader, desc='BATCH')):\n",
    "        # x to device\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # train all model\n",
    "#         errD, D_x, D_G_z1, errG, errEP, errSim, D_G_z2 = train(x)\n",
    "        errD, D_x, D_G_z1, errG, errSim, D_G_z2 = train(x)\n",
    "        epoch_errD += errD\n",
    "        epoch_errG += errG\n",
    "#         epoch_errEP += errEP\n",
    "        epoch_errSim += errSim\n",
    "        epoch_D_x += D_x\n",
    "        epoch_D_G_z1 += D_G_z1\n",
    "        epoch_D_G_z2 += D_G_z2\n",
    "    \n",
    "#     log_str='[%02d]errD: %.4f| D(x): %.4f| D(G(z1)): %.4f| errG: %.4f| errEP: %.4f| errSim: %.4f| D(G(z2)): %.4f' %\\\n",
    "    log_str='[%02d]errD: %.4f| D(x): %.4f| D(G(z1)): %.4f| errG: %.4f| errSim: %.4f| D(G(z2)): %.4f' %\\\n",
    "    (epoch,\n",
    "     epoch_errD/epoch_size,\n",
    "     epoch_D_x/epoch_size,\n",
    "     epoch_D_G_z1/epoch_size,\n",
    "     epoch_errG/epoch_size,\n",
    "#      epoch_errEP/epoch_size,\n",
    "     epoch_errSim/epoch_size,\n",
    "     epoch_D_G_z2/epoch_size\n",
    "     )\n",
    "    \n",
    "    print(log_str)\n",
    "    logging.info(log_str)\n",
    "    \n",
    "    netEP.eval()\n",
    "    netEC.eval()\n",
    "    netG.eval()\n",
    "    netD.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "#         plot_rec(test_x, epoch, 'test')\n",
    "#         plot_analogy(test_x, epoch, 'test')\n",
    "        plot_gen(test_x, epoch, 'test')\n",
    "\n",
    "    # save the model\n",
    "    torch.save({\n",
    "        'netG': netG,\n",
    "        'netEP': netEP,\n",
    "        'netEC': netEC,\n",
    "        'netD': netD},\n",
    "        '%s/model.pth' % log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        with torch.no_grad():\n",
    "            x = torch.transpose(x, 0, 1)\n",
    "            x = x.to(device)\n",
    "            plot_rec(x, 200)\n",
    "            plot_analogy(x, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
